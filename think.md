# çªƒç”µæ£€æµ‹æ¨¡å‹é—®é¢˜è¯Šæ–­ä¸ä¼˜åŒ–æ–¹æ¡ˆ

## ä¸€ã€é¡¹ç›®è®¾è®¡ç†å¿µä¸æ¶æ„

### 1.1 æ ¸å¿ƒè®¾è®¡æ€æƒ³

æœ¬é¡¹ç›®é‡‡ç”¨**"æ—¶é—´åºåˆ—ç¼–ç å™¨ + å¤§è¯­è¨€æ¨¡å‹ (LLM) å¤šæ¨¡æ€èåˆ"**çš„ç«¯åˆ°ç«¯æ¶æ„ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿçªƒç”µæ£€æµ‹æ–¹æ³•çš„ç—›ç‚¹ï¼š

| ä¼ ç»Ÿæ–¹æ³• | ç—›ç‚¹ | æœ¬é¡¹ç›®è§£å†³æ–¹æ¡ˆ |
|---------|------|--------------|
| åŸºäºè§„åˆ™ | å®¹æ˜“è¢«ç»•è¿‡ï¼Œæ— æ³•é€‚åº”æ–°çªƒç”µæ¨¡å¼ | åˆ©ç”¨LLMçš„è¯­ä¹‰ç†è§£å’Œæ¨ç†èƒ½åŠ› |
| æœºå™¨å­¦ä¹  | ç‰¹å¾å·¥ç¨‹å¤æ‚ï¼Œéœ€è¦é¢†åŸŸçŸ¥è¯† | ç«¯åˆ°ç«¯å­¦ä¹ ï¼Œè‡ªåŠ¨æå–ç‰¹å¾ |
| æ·±åº¦å­¦ä¹  | é»‘ç›’æ¨¡å‹ï¼Œæ— æ³•è§£é‡Šåˆ¤æ–­ä¾æ® | LLMå¯ç”Ÿæˆè§£é‡Šæ€§æ–‡æœ¬ |

**è®¾è®¡åˆ›æ–°ç‚¹**ï¼šè®©LLMåƒ"ç”µåŠ›ä¸“å®¶"ä¸€æ ·é˜…è¯»ç”¨ç”µæ•°æ®æŠ¥å‘Šï¼Œç»“åˆæ•°å€¼ç‰¹å¾å’Œæ–‡æœ¬æè¿°åšå‡ºå¯è§£é‡Šçš„åˆ¤æ–­ã€‚

### 1.2 æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ç«¯åˆ°ç«¯çªƒç”µæ£€æµ‹æ¶æ„                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   åŸå§‹æ•°æ®    â”‚
                    â”‚  (48ä¸ªæ—¶é—´ç‚¹) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              ã€æ„ŸçŸ¥å±‚ - Perception Layerã€‘          â”‚
    â”‚  å°†æ—¶é—´åºåˆ—è½¬æ¢ä¸ºLLMèƒ½ç†è§£çš„"è½¯æç¤º" (Soft Prompts)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                â”‚                â”‚
          â–¼                â–¼                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ æ•°å€¼ç¼–ç   â”‚    â”‚ æ–‡æœ¬æç¤º  â”‚    â”‚ èåˆæ¨¡å—  â”‚
    â”‚ (AXIS)   â”‚    â”‚ (Prompt) â”‚    â”‚(Perceiver)â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚               â”‚               â”‚
         â”‚         â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”         â”‚
         â”‚         â”‚ ç»Ÿè®¡ç‰¹å¾  â”‚         â”‚
         â”‚         â”‚ æè¿°æ–‡æœ¬  â”‚         â”‚
         â”‚         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â”‚
         â”‚               â”‚               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Soft Prompts     â”‚
              â”‚ (B, N_tokens, D) â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                ã€è®¤çŸ¥å±‚ - LLMã€‘                     â”‚
    â”‚  æ¥æ”¶ Soft Prompts + Text Embeddings               â”‚
    â”‚  ç”Ÿæˆåˆ¤æ–­ç»“æœï¼š"Theft" æˆ– "Normal"                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   åˆ†ç±»ç»“æœ       â”‚
              â”‚  + è§£é‡Šæ€§æ–‡æœ¬    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 å…³é”®ç»„ä»¶è¯¦è§£

#### **ç»„ä»¶Aï¼šAXISé£æ ¼æ—¶é—´åºåˆ—ç¼–ç å™¨** (`ts_encoder_axis.py`)

**è®¾è®¡ç†å¿µ**ï¼šå€Ÿé‰´AXISè®ºæ–‡ï¼Œä¸“é—¨è®¾è®¡ç”¨äºæå–æ—¶é—´åºåˆ—ç‰¹å¾

**æŠ€æœ¯æ ˆ**ï¼š
- **Patching**: å°†48ä¸ªæ—¶é—´ç‚¹åˆ‡åˆ†æˆpatchï¼ˆé»˜è®¤patch_size=6ï¼‰
- **RoPEä½ç½®ç¼–ç **: æ—‹è½¬ä½ç½®ç¼–ç ï¼Œæ›´å¥½åœ°æ•è·æ—¶é—´å…³ç³»
- **RMSNormå½’ä¸€åŒ–**: æ›¿ä»£LayerNormï¼Œæ›´ç¨³å®š
- **LlamaMLPå‰é¦ˆç½‘ç»œ**: Gated MLPç»“æ„ï¼Œå¢å¼ºè¡¨è¾¾èƒ½åŠ›
- **æ ‡å‡†å¤šå¤´æ³¨æ„åŠ›**: éå› æœæ¨¡å¼ï¼Œé€‚åˆæ—¶é—´åºåˆ—

**è¾“å…¥/è¾“å‡º**ï¼š
- è¾“å…¥: `(Batch, seq_len=48, num_features=1)`
- è¾“å‡º: `(Batch, seq_len, num_features, d_proj=256)`

**é¢„è®­ç»ƒæ”¯æŒ**ï¼š
- æ©ç é‡å»ºå¤´ï¼šé¢„æµ‹è¢«æ©ç ä½ç½®çš„åŸå§‹å€¼ï¼ˆMSEæŸå¤±ï¼‰
- å¼‚å¸¸æ£€æµ‹å¤´ï¼šäºŒåˆ†ç±»ï¼ˆæ­£å¸¸/å¼‚å¸¸ï¼‰

#### **ç»„ä»¶Bï¼šPerceiverèåˆå±‚** (`perceiver_fusion.py`)

**æ ¸å¿ƒé—®é¢˜**ï¼šLLMçš„è¾“å…¥æ˜¯è¯åµŒå…¥ï¼ˆç¦»æ•£æ–‡å­—ï¼‰ï¼Œä½†æ—¶é—´åºåˆ—æ˜¯è¿ç»­æ•°å€¼ï¼Œå¦‚ä½•æ¡¥æ¥ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. **æ—¶é—´å‹ç¼©**: ä½¿ç”¨AdaptiveAvgPool1då°†seq_lenå‹ç¼©åˆ°num_local_tokens
2. **å›ºå®šæç¤º**: å¯å­¦ä¹ çš„å›ºå®štokenåµŒå…¥ï¼ˆå…¨å±€ç‰¹å¾ï¼‰
3. **è·¨æ³¨æ„åŠ›æœºåˆ¶**: æŸ¥è¯¢ä¸ºå›ºå®šæç¤º+å±€éƒ¨æç¤ºï¼Œé”®å€¼ä¸ºæ—¶é—´åºåˆ—ç‰¹å¾
4. **ç»´åº¦å¯¹é½**: å°†d_projæ˜ å°„åˆ°llm_hidden_size

**å…³é”®å®ç°**ï¼š
```python
# ç®€åŒ–ç‰ˆPerceiver
class SimplePerceiverFusion:
    def forward(self, local_embeddings, llm_embeds):
        # local_embeddings: (B, seq_len, num_features, d_proj)
        # 1. åˆå¹¶ç‰¹å¾ç»´åº¦
        features = local_embeddings.mean(dim=2)  # (B, seq_len, d_proj)
        # 2. æŠ•å½±åˆ°LLMç»´åº¦
        features = self.ts_feature_proj(features)  # (B, seq_len, llm_dim)
        # 3. æ—¶é—´å‹ç¼©
        local_tokens = self.temporal_compress(features)  # (B, num_local, llm_dim)
        # 4. Cross-Attention
        queries = torch.cat([local_tokens, fixed_prompts], dim=1)
        attended = self.cross_attn(query=queries, key=local_tokens, value=local_tokens)
        return attended  # (B, num_tokens, llm_dim)
```

#### **ç»„ä»¶Cï¼šæç¤ºå·¥ç¨‹** (`agent_axis.py`)

**ä¸ºä»€ä¹ˆéœ€è¦æ–‡æœ¬æç¤ºï¼Ÿ**
- çº¯æ•°å€¼æ•°æ®å¯¹LLMä¸å‹å¥½
- éœ€è¦å°†æ•°å€¼è½¬æ¢ä¸ºLLMèƒ½ç†è§£çš„æè¿°æ€§è¯­è¨€

**æ–‡æœ¬æç¤ºç»“æ„**ï¼š
```
=== Electricity Usage Analysis ===

[Context] Spring weekday residential load profile.

[Basic Statistics]
  Mean: 2.345 kWh (Historical: 3.123)
  Std: 0.456
  Range: 0.012 - 4.567 kWh

[Pattern Indicators]
  Zero consumption ratio: 15.3%
  Constant usage ratio: 23.4%
  Coefficient of variation: 0.345

[Temporal Distribution]
  Night (0-6h): 25.1%
  Day (9-17h): 45.3%

[Anomaly Detection]
  Abnormal time steps (|z|>2): 3/48

[Risk Signals] high zero consumption, suspiciously stable pattern
```

**ç³»ç»Ÿæç¤º**ï¼š
```python
sys_msg = (
    "You are an expert in electricity theft detection.\n"
    "Analyze the provided electricity usage data objectively.\n"
    "\n"
    "THEFT INDICATORS:\n"
    "- Unusually low or flat consumption\n"
    "- Sudden drops in usage without explanation\n"
    "- Abnormal patterns: many zero values or constant readings\n"
    "- Usage significantly below historical average\n"
    "\n"
    "NORMAL INDICATORS:\n"
    "- Consistent daily/weekly cycles\n"
    "- Weekend vs weekday differences\n"
    "- Seasonal variations matching weather\n"
    "\n"
    "CRITICAL RULES:\n"
    "1. Output ONLY the word 'Theft' or 'Normal'\n"
    "2. Do NOT use <think> tags or explain your reasoning\n"
    "3. Output the single word only, nothing else"
)
```

#### **ç»„ä»¶Dï¼šç«¯åˆ°ç«¯è®­ç»ƒç­–ç•¥**

**é˜¶æ®µ1ï¼šé¢„è®­ç»ƒï¼ˆè‡ªç›‘ç£ï¼‰**
- **ç›®æ ‡**ï¼šå­¦ä¹ æ—¶é—´åºåˆ—çš„é€šç”¨è¡¨ç¤º
- **ä»»åŠ¡1**ï¼šæ©ç é‡å»ºï¼ˆéšæœºæ©ç 15%æ—¶é—´ç‚¹ï¼Œé¢„æµ‹åŸå§‹å€¼ï¼‰
- **ä»»åŠ¡2**ï¼šå¼‚å¸¸æ£€æµ‹ï¼ˆåŸºäºç»Ÿè®¡ç‰¹å¾ç”Ÿæˆä¼ªå¼‚å¸¸æ ‡ç­¾ï¼‰
- **æ•°æ®**ï¼šæ— æ ‡ç­¾çš„æ­£å¸¸æ ·æœ¬ï¼ˆFile1_train.csvï¼‰
- **æŸå¤±**ï¼šMSE + CrossEntropy

**é˜¶æ®µ2ï¼šå¾®è°ƒï¼ˆç›‘ç£å­¦ä¹ ï¼‰**
- **ç›®æ ‡**ï¼šç«¯åˆ°ç«¯çªƒç”µæ£€æµ‹åˆ†ç±»
- **è¾“å…¥**ï¼šSoft Prompts + Text Embeddings
- **è¾“å‡º**ï¼šç”Ÿæˆ"Theft"æˆ–"Normal"
- **æŸå¤±**ï¼šåªè®¡ç®—LLMç”Ÿæˆéƒ¨åˆ†çš„Cross-Entropy Loss
- **æ•°æ®åˆ’åˆ†**ï¼šæŒ‰ç”¨æˆ·åˆ’åˆ†ï¼ˆ70%è®­ç»ƒï¼Œ30%éªŒè¯ï¼‰ï¼Œé¿å…æ•°æ®æ³„éœ²

**æ•°æ®æµå‘è¯¦è§£**ï¼š
```
1. è¾“å…¥: (Batch=32, seq_len=48, features=1)
   â†“
2. AXISç¼–ç å™¨
   - Patching: (32, 8, 6)  â†’  8ä¸ªpatchï¼Œæ¯ä¸ª6ä¸ªç‚¹
   - Embedding: (32, 8, d_model=512)
   - Transformer x8å±‚
   - Projection: (32, 48, 1, d_proj=256)
   â†“
3. Perceiverèåˆ
   - ç‰¹å¾å¹³å‡: (32, 48, 256)
   - æ—¶é—´å‹ç¼©: (32, 20, 2048)  â† local tokens
   - å›ºå®šæç¤º: (32, 10, 2048)  â† fixed tokens
   - Cross-Attention: (32, 30, 2048)
   â†“
4. æ‹¼æ¥è¾“å…¥ LLM
   - Soft Prompts: (32, 30, 2048)
   - Text Embeddings: (32, text_len, 2048)
   - æ‹¼æ¥å: (32, 30+text_len, 2048)
   â†“
5. LLM æ¨ç†
   - è¾“å…¥: æ‹¼æ¥åçš„ embeddings
   - è¾“å‡º: "Theft" æˆ– "Normal" çš„ token
   â†“
6. æŸå¤±è®¡ç®—
   - åªè®¡ç®— LLM è¾“å‡ºéƒ¨åˆ†çš„æŸå¤±
   - Soft Prompts éƒ¨åˆ†æ ‡ç­¾è®¾ä¸º -100ï¼ˆä¸å‚ä¸æŸå¤±ï¼‰
```

---

## äºŒã€å½“å‰ä»£ç å­˜åœ¨çš„ä¸»è¦é—®é¢˜

### 2.1 éšæœºç§å­è®¾ç½®ä¸å®Œæ•´ï¼ˆå¯¼è‡´ç»“æœä¸ç¨³å®šï¼‰

**é—®é¢˜ä½ç½®**: æ‰€æœ‰è®­ç»ƒè„šæœ¬

**é—®é¢˜æè¿°**:
- ä»£ç åªåœ¨`train_pretrain_axis.py`ä¸­éƒ¨åˆ†è®¾ç½®äº†éšæœºç§å­ï¼Œä½†å­˜åœ¨ä»¥ä¸‹ç¼ºé™·ï¼š
  1. `torch.cuda.manual_seed()`æ²¡æœ‰è¢«è®¾ç½®ï¼ŒCUDAæ“ä½œä¸å›ºå®š
  2. `torch.backends.cudnn.benchmark = False`å’Œ`torch.backends.cudnn.deterministic = True`ç¼ºå¤±
  3. `os.environ['PYTHONHASHSEED']`æœªè®¾ç½®
  4. `torch.use_deterministic_algorithms(True)`æœªå¯ç”¨

**å½±å“**:
- å³ä½¿è®¾ç½®äº†`np.random.seed(42)`ï¼Œä¸åŒè¿è¡Œä¹‹é—´çš„éšæœºæ€§ä»ç„¶å­˜åœ¨
- æ¯æ¬¡è®­ç»ƒçš„åˆå§‹åŒ–æƒé‡ä¸åŒï¼Œå¯¼è‡´ç»“æœæ³¢åŠ¨

**ä¿®å¤ä»£ç **:
```python
import os
import random
import numpy as np
import torch

def set_seed(seed=42):
    """è®¾ç½®æ‰€æœ‰éšæœºç§å­ä»¥ç¡®ä¿å®Œå…¨å¯å¤ç°æ€§"""
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # å¦‚æœä½¿ç”¨å¤šGPU
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    torch.use_deterministic_algorithms(True, warn_only=True)
    
    # ä¸ºDataLoaderè®¾ç½®worker seed
    def seed_worker(worker_id):
        worker_seed = torch.initial_seed() % 2**32
        np.random.seed(worker_seed)
        random.seed(worker_seed)
    
    return seed_worker

# ä½¿ç”¨
g = torch.Generator()
g.manual_seed(42)

loader = DataLoader(
    dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=4,
    worker_init_fn=set_seed(42),
    generator=g
)
```

### 2.2 æ•°æ®åŠ è½½å™¨éšæœºæ€§é—®é¢˜

**é—®é¢˜ä½ç½®**: `ElectricityDatasetPretrain.__getitem__()`å’Œ`__init__`

**é—®é¢˜æè¿°**:
- ä½¿ç”¨`torch.randperm()`åœ¨`__init__`ä¸­é‡‡æ ·ï¼Œä½†`DataLoader`çš„`shuffle=True`ä¼šå¯¼è‡´é¢å¤–çš„éšæœºæ€§
- æ©ç ç”Ÿæˆåœ¨`__getitem__`ä¸­æ¯æ¬¡è°ƒç”¨éƒ½æ˜¯éšæœºçš„ï¼Œç¼ºä¹å¤ç°æ€§

**è§£å†³æ–¹æ¡ˆ**:
```python
class ElectricityDatasetPretrain(ElectricityDatasetAXIS):
    def __init__(self, ...):
        super().__init__(...)
        self.epoch = 0  # æ·»åŠ epochè¿½è¸ª
    
    def set_epoch(self, epoch):
        """è®¾ç½®å½“å‰epochï¼Œç”¨äºç¡®å®šæ€§æ©ç ç”Ÿæˆ"""
        self.epoch = epoch
    
    def __getitem__(self, idx):
        vals = self.data_values[idx]
        
        # ä¸ºæ¯ä¸ªidxåˆ›å»ºå›ºå®šçš„éšæœºç§å­
        seed = hash((idx, self.epoch)) % (2**32)
        np.random.seed(seed)
        
        # ç°åœ¨ç”Ÿæˆçš„æ©ç æ˜¯å¯å¤ç°çš„
        mask = self._create_pretrain_mask(len(vals))
        ...

# åœ¨æ¯ä¸ªepochå¼€å§‹æ—¶è°ƒç”¨
for epoch in range(epochs):
    train_dataset.set_epoch(epoch)
    for batch in train_loader:
        ...
```

### 2.3 æŸå¤±è®¡ç®—æ–¹å¼å­˜åœ¨ä¸¥é‡é—®é¢˜

**é—®é¢˜ä½ç½®**: `agent_axis.py`ç¬¬231-272è¡Œ

**é—®é¢˜æè¿°**:
1. **æ ‡ç­¾æ„å»ºé€»è¾‘é”™è¯¯**: ç¬¬250-254è¡Œï¼Œåªæœ‰promptä¹‹åçš„tokenè¢«æ ‡è®°ä¸ºæœ‰æ•ˆï¼Œä½†LLMéœ€è¦ä»æç¤ºç”Ÿæˆå®Œæ•´å›ç­”ï¼Œè¿™ä¼šå¯¼è‡´æ¨¡å‹åªèƒ½å­¦ä¹ ç‰¹å®šæ¨¡å¼
2. **Soft Promptséƒ¨åˆ†è®¾ç½®äº†-100æ ‡ç­¾**: è™½ç„¶æ­£ç¡®ï¼ˆä¸åº”è¯¥è®¡ç®—æŸå¤±ï¼‰ï¼Œä½†ä¸Text Embeddingsçš„æ‹¼æ¥å¯èƒ½å¯¼è‡´æ¢¯åº¦ä¼ æ’­é—®é¢˜

**å…³é”®ä»£ç é—®é¢˜**:
```python
# ç¬¬250-254è¡Œçš„é—®é¢˜
text_labels = torch.full_like(tokens.input_ids, -100)
for i, p_len in enumerate(prompt_lens):
    if p_len < tokens.input_ids.shape[1]:
        text_labels[i, p_len:] = tokens.input_ids[i, p_len:]
text_labels[tokens.attention_mask == 0] = -100
```

**é—®é¢˜åœ¨äº**:
- å®é™…è¾“å…¥ç»™LLMçš„æ˜¯`[Soft Prompts] + [Text Embeddings]`
- æ ‡ç­¾åªå¯¹åº”`Text Embeddings`éƒ¨åˆ†
- ä½†LLMç”Ÿæˆæ—¶çœ‹åˆ°çš„æ˜¯æ‹¼æ¥åçš„è¾“å…¥ï¼Œè¿™å¯èƒ½å¯¼è‡´ä½ç½®ç¼–ç å’Œæ³¨æ„åŠ›è®¡ç®—å‡ºé”™

**æ­£ç¡®åšæ³•**:
```python
# åº”è¯¥è®©LLMå­¦ä¹ ä»Soft Promptså’Œæ–‡æœ¬æç¤ºç”Ÿæˆå›ç­”
# æ ‡ç­¾åº”è¯¥å¯¹åº”å®Œæ•´çš„ç”Ÿæˆç›®æ ‡

# æ„å»ºå®Œæ•´çš„ç›®æ ‡åºåˆ—
full_input = torch.cat([soft_prompts, text_embeds], dim=1)

# æ ‡ç­¾ï¼šsoft_promptséƒ¨åˆ†ä¸º-100ï¼Œtext_embedséƒ¨åˆ†ä¸ºtoken_ids
prefix_labels = torch.full((batch_size, soft_prompt_len), -100, ...)
# å¯¹äºtext_embedsï¼Œåº”è¯¥æ˜¯input_idsåç§»ä¸€ä½ï¼ˆå› æœé¢„æµ‹ï¼‰
# æˆ–è€…ä½¿ç”¨å®Œæ•´çš„targetåºåˆ—
```

### 2.4 æç¤ºå·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰ä¸¥é‡ä¸è¶³

**é—®é¢˜ä½ç½®**: `agent_axis.py`ç¬¬112-131è¡Œ

**é—®é¢˜æè¿°**:
1. **ç³»ç»Ÿæç¤ºè¿‡äºç¬¼ç»Ÿ**: è™½ç„¶åˆ—å‡ºäº†æŒ‡æ ‡ï¼Œä½†ç¼ºä¹å…·ä½“çš„æ•°å€¼æŒ‡å¯¼
2. **æ²¡æœ‰Few-shotç¤ºä¾‹**: LLMæ²¡æœ‰å­¦ä¹ åˆ°å¦‚ä½•åŸºäºå…·ä½“æ•°å€¼åšåˆ¤æ–­
3. **ä¸Šä¸‹æ–‡ç¼ºä¹å…³é”®ä¿¡æ¯**: ç”¨æˆ·çš„å†å²åŸºå‡†ã€ç”¨ç”µæ¨¡å¼ç±»å‹ç­‰

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
few_shot_examples = """
ç¤ºä¾‹1ï¼ˆçªƒç”µï¼‰ï¼š
åˆ†æä¸Šä¸‹æ–‡ï¼š
- å‡å€¼: 0.523 kWhï¼ˆå†å²å‡å€¼: 2.134ï¼‰
- é›¶ç”¨ç”µæ¯”ä¾‹: 45%
- æ’å®šç”¨ç”µæ¯”ä¾‹: 60%
- å¤œé—´ç”¨ç”µå¼‚å¸¸åä½
åˆ¤æ–­ï¼šTheft

ç¤ºä¾‹2ï¼ˆæ­£å¸¸ï¼‰ï¼š
åˆ†æä¸Šä¸‹æ–‡ï¼š
- å‡å€¼: 2.456 kWhï¼ˆå†å²å‡å€¼: 2.345ï¼‰
- é›¶ç”¨ç”µæ¯”ä¾‹: 2%
- ç”¨ç”µæ›²çº¿æœ‰æ˜¼å¤œå·®å¼‚
- å‘¨æœ«ç”¨ç”µé‡ä¸‹é™15%
- ç¬¦åˆå±…æ°‘æ¨¡å¼
åˆ¤æ–­ï¼šNormal

ç¤ºä¾‹3ï¼ˆçªƒç”µï¼‰ï¼š
åˆ†æä¸Šä¸‹æ–‡ï¼š
- ä¸å†å²ç›¸æ¯”ç”¨ç”µé‡çªç„¶ä¸‹é™70%
- å¤§é‡é›¶å€¼è®°å½•ï¼ˆ32/48æ—¶é—´ç‚¹ï¼‰
- ç”¨ç”µæ¨¡å¼ä»æ³¢åŠ¨å˜ä¸ºå¹³å¦
åˆ¤æ–­ï¼šTheft
"""

def construct_prompt(self, axis_hints, user_instructions, ground_truth=None):
    for i, (hint, instr) in enumerate(zip(axis_hints, user_instructions)):
        sys_msg = (
            "ä½ æ˜¯ä¸€ä½ç”µåŠ›çªƒç”µæ£€æµ‹ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„ç”¨ç”µæ•°æ®åˆ†ææ˜¯å¦å­˜åœ¨çªƒç”µè¡Œä¸ºã€‚\n\n"
            "åˆ†æç»´åº¦ï¼š\n"
            "1. ç”¨ç”µé‡å¼‚å¸¸ï¼šä¸å†å²å‡å€¼æ¯”è¾ƒï¼Œåå·®è¶…è¿‡2å€æ ‡å‡†å·®è§†ä¸ºå¼‚å¸¸\n"
            "2. é›¶å€¼æ¯”ä¾‹ï¼šè¶…è¿‡30%çš„é›¶å€¼è®°å½•ä¸ºé«˜é£é™©\n"
            "3. æ’å®šæ¨¡å¼ï¼šè¶…è¿‡50%çš„æ—¶é—´ç‚¹æ•°å€¼ç›¸åŒè§†ä¸ºå¼‚å¸¸\n"
            "4. æ—¶åºæ¨¡å¼ï¼šå¤œé—´(0-6h)å’Œç™½å¤©(9-17h)çš„ç”¨ç”µæ¯”ä¾‹æ˜¯å¦åˆç†\n\n"
            "åˆ¤æ–­æ ‡å‡†ï¼š\n"
            "- å¦‚æœå­˜åœ¨æ˜æ˜¾å¼‚å¸¸æ¨¡å¼ï¼ˆå¦‚å¤§é‡é›¶å€¼ã€æ’å®šè¯»æ•°ã€çªç„¶ä¸‹é™ï¼‰ï¼Œè¾“å‡º 'Theft'\n"
            "- å¦‚æœç”¨ç”µæ›²çº¿ç¬¦åˆæ­£å¸¸å±…æ°‘æ¨¡å¼ï¼ˆæœ‰æ˜¼å¤œå·®å¼‚ã€å‘¨æœ«å·®å¼‚ã€å­£èŠ‚æ³¢åŠ¨ï¼‰ï¼Œè¾“å‡º 'Normal'\n\n"
            "è¾“å‡ºè¦æ±‚ï¼š\n"
            "1. åªè¾“å‡º 'Theft' æˆ– 'Normal'\n"
            "2. ä¸è¦è§£é‡Šï¼Œä¸è¦æ€è€ƒè¿‡ç¨‹ï¼Œä¸è¦ä»»ä½•é¢å¤–æ–‡å­—\n\n"
            f"{few_shot_examples}\n\n"
            "ç°åœ¨è¯·åˆ†æä»¥ä¸‹æ•°æ®ï¼š"
        )
        ...
```

### 2.5 æ•°æ®æ ‡å‡†åŒ–ç­–ç•¥æœ‰å¾…æ”¹è¿›

**é—®é¢˜ä½ç½®**: `main_axis_improved.py`ç¬¬210-225è¡Œ

**é—®é¢˜æè¿°**:
- å½“å‰ä½¿ç”¨`(vals - mean) / std`çš„Z-scoreæ ‡å‡†åŒ–
- å¯¹äºçªƒç”µæ£€æµ‹ï¼Œå¼‚å¸¸å€¼æ­£æ˜¯æˆ‘ä»¬è¦æ£€æµ‹çš„ï¼Œæ ‡å‡†åŒ–ä¼šå‹ç¼©å¼‚å¸¸å€¼çš„ä¿¡æ¯
- æ²¡æœ‰å¤„ç†æç«¯å¼‚å¸¸å€¼ï¼ˆoutliersï¼‰

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
def __getitem__(self, idx):
    vals = self.data_values[idx]
    uid = self.user_ids[idx]
    
    # 1. ä½¿ç”¨ç”¨æˆ·å†å²ç»Ÿè®¡è¿›è¡Œæ ‡å‡†åŒ–
    u_stats = self.user_stats.get(uid, {
        'mean': np.mean(vals),
        'std': np.std(vals) + 1e-6,
        'median': np.median(vals),
        'iqr': np.percentile(vals, 75) - np.percentile(vals, 25) + 1e-6,
        'p95': np.percentile(vals, 95),
        'p5': np.percentile(vals, 5)
    })
    
    # 2. ç¨³å¥æ ‡å‡†åŒ–ï¼ˆRobust Scalingï¼‰- ä½¿ç”¨ä¸­ä½æ•°å’ŒIQRï¼Œå¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ
    median = u_stats.get('median', np.median(vals))
    iqr = u_stats.get('iqr', np.percentile(vals, 75) - np.percentile(vals, 25) + 1e-6)
    vals_normalized = (vals - median) / iqr
    
    # 3. æˆªæ–­æç«¯å€¼ï¼ˆWinsorizationï¼‰
    vals_normalized = np.clip(vals_normalized, -5, 5)
    
    # 4. å¯é€‰ï¼šMin-Maxå½’ä¸€åŒ–åˆ°[0,1]ï¼ˆå¦‚æœéœ€è¦ï¼‰
    # vals_normalized = (vals_normalized - vals_normalized.min()) / (vals_normalized.max() - vals_normalized.min() + 1e-6)
```

### 2.6 ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜æœªå¤„ç†

**é—®é¢˜ä½ç½®**: è®­ç»ƒè„šæœ¬

**é—®é¢˜æè¿°**:
- çªƒç”µæ ·æœ¬é€šå¸¸è¿œå°‘äºæ­£å¸¸æ ·æœ¬ï¼ˆé€šå¸¸æ¯”ä¾‹ä¸º1:5åˆ°1:10ï¼‰
- ä»£ç ä¸­æ²¡æœ‰ä½¿ç”¨åŠ æƒæŸå¤±æˆ–é‡‡æ ·ç­–ç•¥
- è¯„ä¼°æ—¶ä½¿ç”¨ç®€å•çš„å‡†ç¡®ç‡ï¼Œå¯¹ç¨€æœ‰ç±»åˆ«ä¸å…¬å¹³

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. è®¡ç®—ç±»åˆ«æƒé‡
from sklearn.utils.class_weight import compute_class_weight

class_weights = compute_class_weight(
    'balanced', 
    classes=np.unique(all_labels), 
    y=all_labels
)
class_weight_dict = {0: class_weights[0], 1: class_weights[1]}

# 2. åœ¨æŸå¤±å‡½æ•°ä¸­ä½¿ç”¨åŠ æƒæŸå¤±
loss = nn.CrossEntropyLoss(weight=torch.tensor([class_weights[0], class_weights[1]]).to(device))

# 3. æˆ–è€…ä½¿ç”¨WeightedRandomSampler
from torch.utils.data import WeightedRandomSampler

sample_weights = [class_weight_dict[label] for label in dataset.labels]
sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)
loader = DataLoader(dataset, sampler=sampler, ...)

# 4. ä½¿ç”¨Focal Lossï¼ˆæ›´å¥½çš„å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼‰
class FocalLoss(nn.Module):
    """Focal Lossç”¨äºå¤„ç†ç±»åˆ«ä¸å¹³è¡¡"""
    def __init__(self, alpha=0.25, gamma=2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.ce = nn.CrossEntropyLoss(reduction='none')
    
    def forward(self, inputs, targets):
        ce_loss = self.ce(inputs, targets)
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        return focal_loss.mean()

# ä½¿ç”¨Focal Lossï¼ˆalphaåå‘å°‘æ•°ç±»ï¼‰
focal_loss = FocalLoss(alpha=0.75, gamma=2.0)
```

### 2.7 æ¨¡å‹æ¶æ„è®¾è®¡ç¼ºé™·

#### 2.7.1 Perceiverèåˆå±‚é—®é¢˜

**é—®é¢˜ä½ç½®**: `perceiver_fusion.py`ç¬¬282-411è¡Œ

**é—®é¢˜æè¿°**:
1. **Cross-Attentionä½¿ç”¨ä¸å½“**: æŸ¥è¯¢ï¼ˆqueriesï¼‰åº”è¯¥æ˜¯å¯å­¦ä¹ çš„æç¤ºï¼Œé”®å€¼ï¼ˆkeys/valuesï¼‰åº”è¯¥æ˜¯æ—¶é—´åºåˆ—ç‰¹å¾ï¼Œä½†ä»£ç ä¸­å®ç°æ–¹å¼ä¸å¤Ÿä¼˜åŒ–
2. **å›ºå®šæç¤ºï¼ˆfixed promptsï¼‰ä¸å±€éƒ¨æç¤ºï¼ˆlocal promptsï¼‰çš„æ‹¼æ¥æ–¹å¼å¯èƒ½ä¸æ˜¯æœ€ä¼˜çš„**

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
class ImprovedPerceiverFusion(nn.Module):
    def __init__(self, ...):
        super().__init__()
        # ... åˆå§‹åŒ–ä»£ç 
        
        # ä½¿ç”¨åŒå±‚Cross-Attention
        self.local_to_fixed_attn = MultiheadAttention(...)  # å±€éƒ¨â†’å…¨å±€
        self.fixed_to_local_attn = MultiheadAttention(...)  # å…¨å±€â†’å±€éƒ¨
    
    def forward(self, local_embeddings, llm_embeds):
        B = local_embeddings.shape[0]
        
        # 1. åˆå¹¶ç‰¹å¾ç»´åº¦å¹¶æŠ•å½±
        features = local_embeddings.mean(dim=2)  # (B, seq_len, d_proj)
        features = self.ts_feature_proj(features)  # (B, seq_len, llm_dim)
        
        # 2. æ—¶é—´å‹ç¼©
        features = features.transpose(1, 2)  # (B, llm_dim, seq_len)
        local_tokens = self.temporal_compress(features)  # (B, llm_dim, num_local)
        local_tokens = local_tokens.transpose(1, 2)  # (B, num_local, llm_dim)
        
        # 3. åŒå±‚Cross-Attention
        # ç¬¬ä¸€å±‚ï¼šå›ºå®šæç¤ºä»å±€éƒ¨ç‰¹å¾ä¸­å­¦ä¹ 
        fixed_attended = self.local_to_fixed_attn(
            query=self.fixed_prompts.expand(B, -1, -1),  # (B, num_fixed, d)
            key=local_tokens,  # (B, num_local, d)
            value=local_tokens
        )
        
        # ç¬¬äºŒå±‚ï¼šå±€éƒ¨æç¤ºä»å›ºå®šæç¤ºä¸­å­¦ä¹ ï¼ˆåŒå‘äº¤äº’ï¼‰
        local_attended = self.fixed_to_local_attn(
            query=local_tokens,
            key=fixed_attended,
            value=fixed_attended
        )
        
        # 4. åˆå¹¶
        combined = torch.cat([local_attended, fixed_attended], dim=1)
        
        # 5. MLPå¢å¼º
        soft_prompts = self.output_mlp(combined)
        
        return soft_prompts
```

#### 2.7.2 æ—¶é—´åºåˆ—ç¼–ç å™¨è¾“å‡ºçš„ç»´åº¦é—®é¢˜

**é—®é¢˜ä½ç½®**: `ts_encoder_axis.py`ç¬¬269-279è¡Œ

**é—®é¢˜æè¿°**:
- è¾“å‡ºå½¢çŠ¶`(B, seq_len, num_features, d_proj)`åœ¨ä¼ é€’ç»™Perceiveræ—¶éœ€è¦`mean(dim=2)`
- è¿™ä¼šä¸¢å¤±å¤šç‰¹å¾çš„ä¿¡æ¯ï¼Œå¦‚æœæœ‰å¤šä¸ªç‰¹å¾ï¼ˆå¦‚ç”µå‹ã€ç”µæµï¼‰ï¼Œå®ƒä»¬è¢«å¹³å‡äº†

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# ä¸ºæ¯ä¸ªç‰¹å¾å•ç‹¬ç”Ÿæˆæç¤º
class MultiFeaturePerceiverFusion(nn.Module):
    def __init__(self, num_features, d_proj, llm_hidden_size, ...):
        super().__init__()
        self.num_features = num_features
        
        # ä¸ºæ¯ä¸ªç‰¹å¾ä½¿ç”¨ç‹¬ç«‹çš„æŠ•å½±å±‚
        self.feature_proj_layers = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d_proj, llm_hidden_size),
                nn.LayerNorm(llm_hidden_size),
                nn.GELU()
            )
            for _ in range(num_features)
        ])
        
        # æ¯ä¸ªç‰¹å¾ä½¿ç”¨ç‹¬ç«‹çš„å‹ç¼©
        self.temporal_compress_layers = nn.ModuleList([
            nn.AdaptiveAvgPool1d(num_local_tokens // num_features)
            for _ in range(num_features)
        ])
    
    def forward(self, local_embeddings, ...):
        # local_embeddings: (B, seq_len, num_features, d_proj)
        B, seq_len, num_features, d_proj = local_embeddings.shape
        
        feature_prompts = []
        for i in range(num_features):
            feat_i = local_embeddings[:, :, i, :]  # (B, seq_len, d_proj)
            proj_i = self.feature_proj_layers[i](feat_i)  # (B, seq_len, llm_hidden_size)
            
            # æ—¶é—´å‹ç¼©
            proj_i = proj_i.transpose(1, 2)  # (B, llm_dim, seq_len)
            compressed_i = self.temporal_compress_layers[i](proj_i)  # (B, llm_dim, compressed_len)
            compressed_i = compressed_i.transpose(1, 2)  # (B, compressed_len, llm_dim)
            
            feature_prompts.append(compressed_i)
        
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾çš„æç¤º
        all_prompts = torch.cat(feature_prompts, dim=1)  # (B, total_compressed_len, d)
        
        # åç»­Cross-Attention...
```

### 2.8 è®­ç»ƒå’ŒéªŒè¯ç­–ç•¥é—®é¢˜

#### 2.8.1 éªŒè¯é›†åˆ’åˆ†æ–¹å¼

**é—®é¢˜ä½ç½®**: `train_finetune_axis.py`ç¬¬59-79è¡Œ

**é—®é¢˜æè¿°**:
- æŒ‰ç”¨æˆ·åˆ’åˆ†æ˜¯æ­£ç¡®çš„ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰ï¼Œä½†åˆ’åˆ†åæ²¡æœ‰ç¡®ä¿ç±»åˆ«åˆ†å¸ƒçš„ä¸€è‡´æ€§
- è®­ç»ƒé›†å’ŒéªŒè¯é›†å¯èƒ½æœ‰ä¸åŒçš„çªƒç”µæ¯”ä¾‹

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
def split_users_by_ratio(csv_file, train_ratio=0.7, seed=42):
    """æŒ‰ç”¨æˆ·åˆ’åˆ†ï¼Œå¹¶ä¿æŒç±»åˆ«åˆ†å¸ƒä¸€è‡´"""
    df = pd.read_csv(csv_file)
    unique_users = df.iloc[:, 0].astype(str).unique()
    
    # è·å–æ¯ä¸ªç”¨æˆ·çš„æ ‡ç­¾ï¼ˆæ˜¯å¦çªƒç”µï¼‰
    user_labels = {}
    for user in unique_users:
        user_data = df[df.iloc[:, 0].astype(str) == user]
        # å¦‚æœç”¨æˆ·æœ‰ä»»ä½•ä¸€å¤©è¢«æ ‡è®°ä¸ºçªƒç”µï¼Œåˆ™è®¤ä¸ºæ˜¯çªƒç”µç”¨æˆ·
        user_labels[user] = 1 if user_data['flag'].max() > 0 else 0
    
    # æŒ‰æ ‡ç­¾åˆ†å±‚é‡‡æ ·
    theft_users = [u for u, l in user_labels.items() if l == 1]
    normal_users = [u for u, l in user_labels.items() if l == 0]
    
    np.random.seed(seed)
    np.random.shuffle(theft_users)
    np.random.shuffle(normal_users)
    
    n_train_theft = int(len(theft_users) * train_ratio)
    n_train_normal = int(len(normal_users) * train_ratio)
    
    train_users = theft_users[:n_train_theft] + normal_users[:n_train_normal]
    val_users = theft_users[n_train_theft:] + normal_users[n_train_normal:]
    
    print(f"è®­ç»ƒé›†: {len(train_users)}ç”¨æˆ· (çªƒç”µ: {n_train_theft}, æ­£å¸¸: {n_train_normal})")
    print(f"éªŒè¯é›†: {len(val_users)}ç”¨æˆ· (çªƒç”µ: {len(theft_users)-n_train_theft}, æ­£å¸¸: {len(normal_users)-n_train_normal})")
    
    return train_users, val_users
```

#### 2.8.2 æ—©åœç­–ç•¥è¿‡äºç®€å•

**é—®é¢˜ä½ç½®**: `train_finetune_axis.py`ç¬¬217-318è¡Œ

**é—®é¢˜æè¿°**:
- åªåŸºäºéªŒè¯æŸå¤±æ—©åœï¼Œæ²¡æœ‰è€ƒè™‘å…¶ä»–æŒ‡æ ‡
- å¯¹äºçªƒç”µæ£€æµ‹ï¼Œåº”è¯¥ä¸»è¦å…³æ³¨WF1ã€MAP@Kç­‰æŒ‡æ ‡

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨ç»¼åˆæŒ‡æ ‡è¿›è¡Œæ—©åœ
from utils.metrics import TheftDetectionMetrics

def evaluate_model(agent, val_loader, device):
    """å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    metrics = TheftDetectionMetrics()
    
    with torch.no_grad():
        for batch in val_loader:
            targets = batch['label'].to(device)
            target_texts = ["Theft" if t == 1 else "Normal" for t in targets]
            instructions = ["Analyze this user's electricity usage pattern."] * len(targets)
            
            responses, _, theft_scores = agent.generate(
                batch, instructions, return_scores=True, debug=False
            )
            
            for i in range(len(targets)):
                true_label = "Theft" if targets[i] == 1 else "Normal"
                pred_text = responses[i].strip().lower()
                pred_label = "Theft" if "theft" in pred_text else "Normal"
                score = theft_scores[i] if theft_scores else 0.5
                
                metrics.update(true_label, pred_label, score, user_id=i)
    
    results = metrics.compute()
    
    # ç»¼åˆè¯„åˆ†
    composite_score = (
        0.3 * results['auc'] +
        0.3 * results['map@40'] +
        0.2 * results['wf1'] +
        0.2 * results['f1_theft']  # ç‰¹åˆ«å…³æ³¨çªƒç”µç±»åˆ«çš„å¬å›
    )
    
    return composite_score, results

# åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨
best_composite_score = 0
for epoch in range(epochs):
    # ... è®­ç»ƒä»£ç  ...
    
    # éªŒè¯
    composite_score, val_results = evaluate_model(agent, val_loader, device)
    
    print(f"Validation - Composite: {composite_score:.4f}, AUC: {val_results['auc']:.4f}, MAP@40: {val_results['map@40']:.4f}")
    
    # æ—©åœåˆ¤æ–­
    if composite_score > best_composite_score:
        best_composite_score = composite_score
        patience_counter = 0
        torch.save(checkpoint, f"{checkpoint_dir}/finetune_{model_config_name.lower()}_best.pth")
    else:
        patience_counter += 1
        if patience_counter >= patience:
            print(f"Early stopping triggered")
            break
```

### 2.9 æµ‹è¯•å’Œæ¨ç†é—®é¢˜

#### 2.9.1 æµ‹è¯•æ—¶ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼ä½†ä¸ä¿å­˜

**é—®é¢˜ä½ç½®**: `test_axis_improved.py`ç¬¬169-189è¡Œ

**é—®é¢˜æè¿°**:
- ä»£ç è‡ªé€‚åº”åœ°æ‰¾åˆ°æœ€ä½³é˜ˆå€¼ï¼Œä½†è¿™ä¸ªé˜ˆå€¼æ²¡æœ‰è¢«ä¿å­˜æˆ–ç”¨äºåç»­æ¨ç†
- æ¯æ¬¡æµ‹è¯•éƒ½è¦é‡æ–°è®¡ç®—æœ€ä½³é˜ˆå€¼

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# åœ¨å¾®è°ƒé˜¶æ®µå°±æ‰¾åˆ°æœ€ä½³é˜ˆå€¼
def find_optimal_threshold(agent, val_loader, device):
    """åœ¨éªŒè¯é›†ä¸Šæ‰¾åˆ°æœ€ä½³é˜ˆå€¼"""
    all_scores = []
    all_labels = []
    
    with torch.no_grad():
        for batch in val_loader:
            _, _, scores = agent.generate(
                batch, 
                ["Analyze this user's electricity usage pattern."] * len(batch['label']),
                return_scores=True
            )
            all_scores.extend(scores)
            all_labels.extend(batch['label'].cpu().numpy())
    
    # æœç´¢æœ€ä½³é˜ˆå€¼
    best_thresh = 0.5
    best_f1 = 0
    best_results = {}
    
    for thresh in np.arange(0.1, 0.9, 0.01):
        preds = [1 if s > thresh else 0 for s in all_scores]
        f1 = f1_score(all_labels, preds)
        if f1 > best_f1:
            best_f1 = f1
            best_thresh = thresh
            best_results = {
                'threshold': thresh,
                'f1': f1,
                'precision': precision_score(all_labels, preds),
                'recall': recall_score(all_labels, preds)
            }
    
    print(f"Optimal threshold: {best_thresh:.2f} (F1: {best_f1:.4f})")
    return best_thresh, best_results

# ä¿å­˜åˆ°æ£€æŸ¥ç‚¹
best_thresh, thresh_results = find_optimal_threshold(agent, val_loader, device)

checkpoint = {
    'perception': agent.perception.state_dict(),
    'optimal_threshold': best_thresh,
    'threshold_results': thresh_results,
    'epoch': epoch,
    'loss': avg_loss,
    'config': config,
    'config_name': model_config_name
}
```

### 2.10 è°ƒè¯•å’Œç›‘æ§ä¸è¶³

**é—®é¢˜æè¿°**:
- æ²¡æœ‰TensorBoardæˆ–WandBé›†æˆ
- è®­ç»ƒè¿‡ç¨‹ä¸­æ²¡æœ‰å¯è§†åŒ–ä¸­é—´ç»“æœ
- éš¾ä»¥è¯Šæ–­æ¨¡å‹å­¦ä¹ è¿‡ç¨‹

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
from torch.utils.tensorboard import SummaryWriter
import time

# åˆå§‹åŒ–writer
writer = SummaryWriter(log_dir=f'runs/{model_config_name}_{int(time.time())}')

# è®­ç»ƒå¾ªç¯ä¸­è®°å½•
for epoch in range(epochs):
    # ... è®­ç»ƒä»£ç  ...
    
    # è®°å½•æŸå¤±
    writer.add_scalar('Loss/train', avg_loss, epoch)
    writer.add_scalar('Loss/val', avg_val_loss, epoch)
    
    # è®°å½•å­¦ä¹ ç‡
    writer.add_scalar('Learning_rate', current_lr, epoch)
    
    # è®°å½•æŒ‡æ ‡
    writer.add_scalar('Metrics/AUC', val_results['auc'], epoch)
    writer.add_scalar('Metrics/MAP@40', val_results['map@40'], epoch)
    writer.add_scalar('Metrics/WF1', val_results['wf1'], epoch)
    writer.add_scalar('Metrics/F1_Theft', val_results['f1_theft'], epoch)
    
    # è®°å½•æ¨¡å‹æƒé‡åˆ†å¸ƒ
    for name, param in agent.perception.named_parameters():
        writer.add_histogram(f'weights/{name}', param, epoch)
        if param.grad is not None:
            writer.add_histogram(f'grads/{name}', param.grad, epoch)

# å…³é—­writer
writer.close()
```

---

## ä¸‰ã€æ¨èçš„æ•´ä½“ä¼˜åŒ–æ¶æ„

### 3.1 æ•°æ®é¢„å¤„ç†æµç¨‹é‡æ„

```
åŸå§‹æ•°æ®
  â†“
1. æ•°æ®æ¸…æ´—ï¼ˆå¤„ç†ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ï¼‰
  â†“
2. ç”¨æˆ·å†å²ç»Ÿè®¡è®¡ç®—ï¼ˆmean, std, median, IQR, percentilesï¼‰
  â†“
3. ç¨³å¥æ ‡å‡†åŒ–ï¼ˆRobust Scalingï¼‰
  â†“
4. Winsorizationï¼ˆæˆªæ–­æç«¯å€¼ï¼‰
  â†“
5. æ—¶é—´ç‰¹å¾å·¥ç¨‹ï¼ˆday of week, hour, seasonï¼‰
  â†“
6. åˆ›å»ºå¤šç‰¹å¾è¾“å…¥ï¼ˆåŸå§‹å€¼ + å·®åˆ† + ç»Ÿè®¡ç‰¹å¾ï¼‰
  â†“
è¾“å…¥åˆ°æ¨¡å‹
```

### 3.2 æ¨¡å‹æ¶æ„ä¼˜åŒ–

```
æ—¶é—´åºåˆ—ç¼–ç å™¨ï¼ˆAXISï¼‰
  - RoPEä½ç½®ç¼–ç 
  - RMSNormå½’ä¸€åŒ–
  - LlamaMLPå‰é¦ˆç½‘ç»œ
  - Multi-head Attention
  â†“
è¾“å‡º: (B, seq_len, num_features, d_proj)
  â†“
Perceiverèåˆå±‚ï¼ˆæ”¹è¿›ç‰ˆï¼‰
  - å¤šç‰¹å¾ç‹¬ç«‹æŠ•å½±ï¼ˆå¦‚æœä½¿ç”¨å¤šç‰¹å¾ï¼‰
  - åŒå±‚Cross-Attention
  - æ—¶é—´å‹ç¼©
  â†“
è¾“å‡º: (B, num_tokens, llm_hidden_size)
  â†“
ä¸æ–‡æœ¬Embeddingæ‹¼æ¥
  â†“
LLMï¼ˆQwen3ï¼‰
  â†“
è¾“å‡º: "Theft" or "Normal"
```

### 3.3 è®­ç»ƒæµç¨‹ä¼˜åŒ–

```
é˜¶æ®µ1: é¢„è®­ç»ƒï¼ˆè‡ªç›‘ç£ï¼‰
â”œâ”€â”€ æ©ç é‡å»ºä»»åŠ¡ (MSE)
â”œâ”€â”€ å¼‚å¸¸æ£€æµ‹ä»»åŠ¡ (BCE)
â”œâ”€â”€ å¯¹æ¯”å­¦ä¹ ä»»åŠ¡ï¼ˆå¯é€‰ï¼Œè¿›ä¸€æ­¥å­¦ä¹ åˆ¤åˆ«æ€§ç‰¹å¾ï¼‰
â””â”€â”€ ä½¿ç”¨AdamW + CosineAnnealingWarmRestarts

é˜¶æ®µ2: å¾®è°ƒï¼ˆç›‘ç£å­¦ä¹ ï¼‰
â”œâ”€â”€ ä½¿ç”¨åŠ æƒé‡‡æ ·æˆ–åŠ æƒæŸå¤±å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
â”œâ”€â”€ è”åˆæŸå¤±: L_ce + Î» * L_focal
â”œâ”€â”€ åˆ†å±‚å­¦ä¹ ç‡ï¼ˆç¼–ç å™¨lrå°ï¼Œèåˆå±‚lrå¤§ï¼‰
â”œâ”€â”€ æ—©åœåŸºäºç»¼åˆæŒ‡æ ‡ï¼ˆWF1 + MAP@K + AUCï¼‰
â”œâ”€â”€ åŠ¨æ€é˜ˆå€¼å­¦ä¹ å¹¶ä¿å­˜
â””â”€â”€ ä½¿ç”¨éªŒè¯é›†å…¨é¢è¯„ä¼°

é˜¶æ®µ3: æµ‹è¯•ä¸éƒ¨ç½²
â”œâ”€â”€ åŠ è½½æœ€ä¼˜é˜ˆå€¼
â”œâ”€â”€ é›†æˆæ¨ç†ï¼ˆå¯é€‰ï¼Œå¤šä¸ªæ¨¡å‹æŠ•ç¥¨ï¼‰
â””â”€â”€ ç»“æœå¯è§†åŒ–ä¸è§£é‡Š
```

---

## å››ã€ä¼˜å…ˆä¿®å¤åˆ—è¡¨ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰

### ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼ˆå¿…é¡»ä¿®å¤ï¼‰

1. **å®Œå–„éšæœºç§å­è®¾ç½®** - ç¡®ä¿å¯å¤ç°æ€§
   - ä½ç½®ï¼šæ‰€æœ‰è®­ç»ƒè„šæœ¬å¼€å¤´
   - é¢„è®¡æå‡ï¼šç»“æœç¨³å®šæ€§

2. **ä¿®å¤æŸå¤±è®¡ç®—é€»è¾‘** - å½“å‰å®ç°å¯èƒ½å¯¼è‡´è®­ç»ƒå¤±è´¥
   - ä½ç½®ï¼š`agent_axis.py` forwardæ–¹æ³•
   - é¢„è®¡æå‡ï¼šè®­ç»ƒæœ‰æ•ˆæ€§

3. **æ·»åŠ ç±»åˆ«å¹³è¡¡å¤„ç†** - åŠ æƒæŸå¤±æˆ–é‡‡æ ·
   - ä½ç½®ï¼šè®­ç»ƒè„šæœ¬
   - é¢„è®¡æå‡ï¼šçªƒç”µå¬å›ç‡ +15-20%

4. **æ”¹è¿›æ•°æ®æ ‡å‡†åŒ–** - ä½¿ç”¨Robust Scaling + Winsorization
   - ä½ç½®ï¼š`main_axis_improved.py` __getitem__
   - é¢„è®¡æå‡ï¼šå¼‚å¸¸å€¼æ£€æµ‹èƒ½åŠ›

5. **ä¼˜åŒ–æç¤ºå·¥ç¨‹** - æä¾›Few-shotç¤ºä¾‹å’Œæ›´æ˜ç¡®çš„æŒ‡å¯¼
   - ä½ç½®ï¼š`agent_axis.py` construct_prompt
   - é¢„è®¡æå‡ï¼šLLMç†è§£èƒ½åŠ› +10-15%

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼ˆæ˜¾è‘—æå‡æ•ˆæœï¼‰

6. **æ”¹è¿›Perceiverèåˆå±‚** - ä¿®å¤Cross-Attentioné€»è¾‘
   - ä½ç½®ï¼š`perceiver_fusion.py`
   - é¢„è®¡æå‡ï¼šç‰¹å¾èåˆè´¨é‡

7. **åˆ†å±‚å­¦ä¹ ç‡** - ç¼–ç å™¨ä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡
   - ä½ç½®ï¼šè®­ç»ƒè„šæœ¬ä¼˜åŒ–å™¨è®¾ç½®
   - é¢„è®¡æå‡ï¼šè®­ç»ƒç¨³å®šæ€§

8. **æ·»åŠ TensorBoardç›‘æ§** - ä¾¿äºè°ƒè¯•
   - ä½ç½®ï¼šè®­ç»ƒè„šæœ¬
   - é¢„è®¡æå‡ï¼šè°ƒè¯•æ•ˆç‡

9. **åœ¨éªŒè¯é›†ä¸Šæ‰¾åˆ°å¹¶ä¿å­˜æœ€ä½³é˜ˆå€¼** - æå‡æ¨ç†æ€§èƒ½
   - ä½ç½®ï¼šè®­ç»ƒè„šæœ¬éªŒè¯é˜¶æ®µ
   - é¢„è®¡æå‡ï¼šF1åˆ†æ•° +5-10%

10. **æ”¹è¿›æ—©åœç­–ç•¥** - åŸºäºç»¼åˆæŒ‡æ ‡
    - ä½ç½®ï¼šè®­ç»ƒè„šæœ¬
    - é¢„è®¡æå‡ï¼šæ¨¡å‹é€‰æ‹©è´¨é‡

### ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼ˆé”¦ä¸Šæ·»èŠ±ï¼‰

11. **æ·»åŠ å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒä»»åŠ¡** - è¿›ä¸€æ­¥æå‡ç‰¹å¾è´¨é‡
12. **é›†æˆæ¨ç†ï¼ˆEnsembleï¼‰** - å¤šæ¨¡å‹æŠ•ç¥¨
13. **æ¨¡å‹è§£é‡Šæ€§ï¼ˆAttentionå¯è§†åŒ–ï¼‰** - ç†è§£æ¨¡å‹å†³ç­–
14. **æ”¯æŒå¤šå˜é‡è¾“å…¥** - å¦‚æœæœ‰ç”µå‹ã€ç”µæµç­‰é¢å¤–æ•°æ®

---

## äº”ã€å…³é”®ä»£ç ä¿®å¤ç¤ºä¾‹

### 5.1 å®Œæ•´çš„éšæœºç§å­è®¾ç½®

```python
import os
import random
import numpy as np
import torch

def set_seed(seed=42):
    """è®¾ç½®æ‰€æœ‰éšæœºç§å­ä»¥ç¡®ä¿å®Œå…¨å¯å¤ç°æ€§"""
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # å¦‚æœä½¿ç”¨å¤šGPU
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    torch.use_deterministic_algorithms(True, warn_only=True)
    
    # ä¸ºDataLoaderè®¾ç½®worker seed
    def seed_worker(worker_id):
        worker_seed = torch.initial_seed() % 2**32
        np.random.seed(worker_seed)
        random.seed(worker_seed)
    
    return seed_worker

# åœ¨æ¯ä¸ªè„šæœ¬å¼€å¤´è°ƒç”¨
set_seed(42)

# ä½¿ç”¨DataLoaderæ—¶
g = torch.Generator()
g.manual_seed(42)

loader = DataLoader(
    dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=4,
    worker_init_fn=set_seed(42),
    generator=g
)
```

### 5.2 Focal Lossï¼ˆå¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼‰

```python
class FocalLoss(nn.Module):
    """Focal Lossç”¨äºå¤„ç†ç±»åˆ«ä¸å¹³è¡¡"""
    def __init__(self, alpha=0.25, gamma=2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.ce = nn.CrossEntropyLoss(reduction='none')
    
    def forward(self, inputs, targets):
        ce_loss = self.ce(inputs, targets)
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        return focal_loss.mean()

# åœ¨å¾®è°ƒæ—¶ä½¿ç”¨
from utils.losses import FocalLoss
focal_loss = FocalLoss(alpha=0.75, gamma=2.0)  # alphaåå‘å°‘æ•°ç±»ï¼ˆçªƒç”µï¼‰

# è”åˆæŸå¤±
loss = ce_loss + 0.5 * focal_loss
```

### 5.3 åˆ†å±‚å­¦ä¹ ç‡

```python
# ä¸ºä¸åŒå±‚è®¾ç½®ä¸åŒå­¦ä¹ ç‡
param_groups = [
    {
        'params': agent.perception.numerical_stream.encoder.parameters(),
        'lr': lr * 0.1  # ç¼–ç å™¨ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡
    },
    {
        'params': agent.perception.fusion.parameters(),
        'lr': lr  # èåˆå±‚ä½¿ç”¨æ ‡å‡†å­¦ä¹ ç‡
    }
]

optimizer = AdamW(param_groups, weight_decay=0.01)
```

### 5.4 æ”¹è¿›çš„æç¤ºæ„å»ºï¼ˆåŒ…å«Few-shotç¤ºä¾‹ï¼‰

```python
few_shot_examples = """
ç¤ºä¾‹1ï¼ˆçªƒç”µï¼‰ï¼š
åˆ†æä¸Šä¸‹æ–‡ï¼š
- å‡å€¼: 0.523 kWhï¼ˆå†å²å‡å€¼: 2.134ï¼‰
- é›¶ç”¨ç”µæ¯”ä¾‹: 45%
- æ’å®šç”¨ç”µæ¯”ä¾‹: 60%
- å¤œé—´ç”¨ç”µå¼‚å¸¸åä½
åˆ¤æ–­ï¼šTheft

ç¤ºä¾‹2ï¼ˆæ­£å¸¸ï¼‰ï¼š
åˆ†æä¸Šä¸‹æ–‡ï¼š
- å‡å€¼: 2.456 kWhï¼ˆå†å²å‡å€¼: 2.345ï¼‰
- é›¶ç”¨ç”µæ¯”ä¾‹: 2%
- ç”¨ç”µæ›²çº¿æœ‰æ˜¼å¤œå·®å¼‚
- å‘¨æœ«ç”¨ç”µé‡ä¸‹é™15%
- ç¬¦åˆå±…æ°‘æ¨¡å¼
åˆ¤æ–­ï¼šNormal

ç¤ºä¾‹3ï¼ˆçªƒç”µï¼‰ï¼š
åˆ†æä¸Šä¸‹æ–‡ï¼š
- ä¸å†å²ç›¸æ¯”ç”¨ç”µé‡çªç„¶ä¸‹é™70%
- å¤§é‡é›¶å€¼è®°å½•ï¼ˆ32/48æ—¶é—´ç‚¹ï¼‰
- ç”¨ç”µæ¨¡å¼ä»æ³¢åŠ¨å˜ä¸ºå¹³å¦
åˆ¤æ–­ï¼šTheft
"""

def construct_prompt(self, axis_hints, user_instructions, ground_truth=None):
    for i, (hint, instr) in enumerate(zip(axis_hints, user_instructions)):
        sys_msg = (
            "ä½ æ˜¯ä¸€ä½ç”µåŠ›çªƒç”µæ£€æµ‹ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„ç”¨ç”µæ•°æ®åˆ†ææ˜¯å¦å­˜åœ¨çªƒç”µè¡Œä¸ºã€‚\n\n"
            "åˆ†æç»´åº¦ï¼š\n"
            "1. ç”¨ç”µé‡å¼‚å¸¸ï¼šä¸å†å²å‡å€¼æ¯”è¾ƒï¼Œåå·®è¶…è¿‡2å€æ ‡å‡†å·®è§†ä¸ºå¼‚å¸¸\n"
            "2. é›¶å€¼æ¯”ä¾‹ï¼šè¶…è¿‡30%çš„é›¶å€¼è®°å½•ä¸ºé«˜é£é™©\n"
            "3. æ’å®šæ¨¡å¼ï¼šè¶…è¿‡50%çš„æ—¶é—´ç‚¹æ•°å€¼ç›¸åŒè§†ä¸ºå¼‚å¸¸\n"
            "4. æ—¶åºæ¨¡å¼ï¼šå¤œé—´(0-6h)å’Œç™½å¤©(9-17h)çš„ç”¨ç”µæ¯”ä¾‹æ˜¯å¦åˆç†\n\n"
            "åˆ¤æ–­æ ‡å‡†ï¼š\n"
            "- å¦‚æœå­˜åœ¨æ˜æ˜¾å¼‚å¸¸æ¨¡å¼ï¼ˆå¦‚å¤§é‡é›¶å€¼ã€æ’å®šè¯»æ•°ã€çªç„¶ä¸‹é™ï¼‰ï¼Œè¾“å‡º 'Theft'\n"
            "- å¦‚æœç”¨ç”µæ›²çº¿ç¬¦åˆæ­£å¸¸å±…æ°‘æ¨¡å¼ï¼ˆæœ‰æ˜¼å¤œå·®å¼‚ã€å‘¨æœ«å·®å¼‚ã€å­£èŠ‚æ³¢åŠ¨ï¼‰ï¼Œè¾“å‡º 'Normal'\n\n"
            "è¾“å‡ºè¦æ±‚ï¼š\n"
            "1. åªè¾“å‡º 'Theft' æˆ– 'Normal'\n"
            "2. ä¸è¦è§£é‡Šï¼Œä¸è¦æ€è€ƒè¿‡ç¨‹ï¼Œä¸è¦ä»»ä½•é¢å¤–æ–‡å­—\n\n"
            f"{few_shot_examples}\n\n"
            "ç°åœ¨è¯·åˆ†æä»¥ä¸‹æ•°æ®ï¼š"
        )
        
        user_content = f"åˆ†æä¸Šä¸‹æ–‡ï¼š\n{hint}\n\næŒ‡ä»¤ï¼š\n{instr}"
        
        messages = [
            {"role": "system", "content": sys_msg},
            {"role": "user", "content": user_content}
        ]
        # ... å‰©ä½™ä»£ç 
```

---

## å…­ã€é¢„æœŸæ•ˆæœ

å®æ–½ä¸Šè¿°ä¼˜åŒ–åï¼Œé¢„æœŸå¯ä»¥å®ç°ï¼š

| æŒ‡æ ‡ | å½“å‰æ°´å¹³ | ä¼˜åŒ–åç›®æ ‡ | æå‡å¹…åº¦ |
|------|---------|-----------|---------|
| **ç»“æœç¨³å®šæ€§** | æ ‡å‡†å·® ~10% | æ ‡å‡†å·® < 2% | 5x |
| **AUC** | ~0.65 | ~0.85+ | +30% |
| **MAP@40** | ~0.20 | ~0.50+ | +150% |
| **WF1** | ~0.60 | ~0.80+ | +33% |
| **çªƒç”µå¬å›ç‡** | ~50% | ~80%+ | +60% |

---

## ä¸ƒã€å®æ–½å»ºè®®

1. **åˆ†é˜¶æ®µå®æ–½**ï¼šå…ˆä¿®å¤éšæœºç§å­å’ŒæŸå¤±è®¡ç®—ï¼Œå†ä¼˜åŒ–æ¶æ„
2. **ä½¿ç”¨Gitç®¡ç†**ï¼šæ¯æ¬¡ä¿®æ”¹åæäº¤ï¼Œä¾¿äºå›æ»š
3. **å°æ•°æ®é›†éªŒè¯**ï¼šå…ˆç”¨1000ä¸ªæ ·æœ¬å¿«é€ŸéªŒè¯ä¿®æ”¹æ•ˆæœ
4. **A/Bæµ‹è¯•**ï¼šå¯¹æ¯”æ”¹è¿›å‰åçš„æŒ‡æ ‡å˜åŒ–
5. **è®°å½•å®éªŒ**ï¼šä½¿ç”¨è¡¨æ ¼è®°å½•æ¯æ¬¡å®éªŒçš„é…ç½®å’Œç»“æœ

### å®æ–½é¡ºåºå»ºè®®ï¼š

**ç¬¬ä¸€é˜¶æ®µï¼ˆåŸºç¡€è®¾æ–½ï¼‰**ï¼š
- [ ] ä¿®å¤éšæœºç§å­
- [ ] æ·»åŠ TensorBoardç›‘æ§
- [ ] æ”¹è¿›æ•°æ®æ ‡å‡†åŒ–

**ç¬¬äºŒé˜¶æ®µï¼ˆè®­ç»ƒä¼˜åŒ–ï¼‰**ï¼š
- [ ] ä¿®å¤æŸå¤±è®¡ç®—
- [ ] æ·»åŠ ç±»åˆ«å¹³è¡¡å¤„ç†
- [ ] å®ç°åˆ†å±‚å­¦ä¹ ç‡

**ç¬¬ä¸‰é˜¶æ®µï¼ˆæ¶æ„ä¼˜åŒ–ï¼‰**ï¼š
- [ ] æ”¹è¿›æç¤ºå·¥ç¨‹
- [ ] ä¼˜åŒ–Perceiverèåˆå±‚
- [ ] æ”¹è¿›æ—©åœç­–ç•¥

**ç¬¬å››é˜¶æ®µï¼ˆå®Œå–„ï¼‰**ï¼š
- [ ] ä¿å­˜æœ€ä½³é˜ˆå€¼
- [ ] æ·»åŠ å¯¹æ¯”å­¦ä¹ 
- [ ] æ¨¡å‹è§£é‡Šæ€§

---

*åˆ†æå®Œæˆæ—¶é—´: 2025å¹´2æœˆ*
*åˆ†æå¸ˆ: çªƒç”µæ£€æµ‹LLMä¸“å®¶*
